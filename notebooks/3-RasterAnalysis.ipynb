{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Edited by Sizhuo Li\n",
    "   \n",
    "   Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:46:10.820921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:46:14.925224: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-01 15:46:14.927175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-01 15:46:15.183531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3d:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:15.184041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:3e:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:15.184499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:15.184950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:15.184981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-01 15:46:15.190528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-01 15:46:15.190590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-01 15:46:15.194007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-01 15:46:15.195991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-01 15:46:15.220848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-01 15:46:15.222330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-01 15:46:15.229851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-01 15:46:15.235844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-04-01 15:46:15.237082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-01 15:46:15.244782: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-01 15:46:16.079698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3d:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:16.080155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:3e:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:16.080563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:88:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:16.080951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2022-04-01 15:46:16.081017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-01 15:46:16.081043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-01 15:46:16.081054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-01 15:46:16.081065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-01 15:46:16.081076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-01 15:46:16.081088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-01 15:46:16.081099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-01 15:46:16.081110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-01 15:46:16.083981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-04-01 15:46:16.084021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-01 15:46:17.537064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-01 15:46:17.537090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 \n",
      "2022-04-01 15:46:17.537107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y \n",
      "2022-04-01 15:46:17.537111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y \n",
      "2022-04-01 15:46:17.537114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y \n",
      "2022-04-01 15:46:17.537118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N \n",
      "2022-04-01 15:46:17.539723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3d:00.0, compute capability: 7.0)\n",
      "2022-04-01 15:46:17.541233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30132 MB memory) -> physical GPU (device: 1, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0)\n",
      "2022-04-01 15:46:17.542271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30132 MB memory) -> physical GPU (device: 2, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:88:00.0, compute capability: 7.0)\n",
      "2022-04-01 15:46:17.543354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30132 MB memory) -> physical GPU (device: 3, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import geopandas as gps\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "import numpy as np               # numerical array manipulation\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from itertools import product\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo, image_normalize\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.split_frames import split_dataset\n",
    "from core.visualize import display_images\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/RasterAnalysis.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from configTemplate import RasterAnalysis\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder \n",
    "# Eg. from configLargeCluster import RasterAnalysis\n",
    "\n",
    "config = RasterAnalysis.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(\"Please enter exact name of user: \").lower()\n",
    "    \n",
    "config.output_dir = config.output_dir + '/' + username\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.makedirs(config.output_dir)\n",
    "\n",
    "config.input_image_dir = config.input_image_dir + '/' + username\n",
    "\n",
    "config.trained_model_path = config.model_path + '/' + username\n",
    "\n",
    "while True:\n",
    "    model_name = input(\"Please enter exact name of model file: \").lower().strip()\n",
    "    if not os.path.exists(config.trained_model_path + '/' + model_name):\n",
    "        print(\"Error: Model not found. Please try again.\")\n",
    "    else:\n",
    "        config.trained_model_path = config.trained_model_path + '/' + model_name\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "OPTIMIZER = adaDelta\n",
    "model = load_model(config.trained_model_path, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy, 'specificity':specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=tversky, metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch to the total results of a larger area. The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "def addTOResult(res, prediction, row, col, he, wi, operator = 'MAX'):\n",
    "    currValue = res[row:row+he, col:col+wi]\n",
    "    newPredictions = prediction[:he, :wi]\n",
    "# IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if operator == 'MIN': # Takes the min of current prediction and new prediction for each pixel\n",
    "        currValue [currValue == -1] = 1 #Replace -1 with 1 in case of MIN\n",
    "        resultant = np.minimum(currValue, newPredictions) \n",
    "    elif operator == 'MAX':\n",
    "        resultant = np.maximum(currValue, newPredictions)\n",
    "    else: #operator == 'REPLACE':\n",
    "        resultant = newPredictions    \n",
    "# Alternative approach; Lets assume that quality of prediction is better in the centre of the image than on the edges\n",
    "# We use numbers from 1-5 to denote the quality, where 5 is the best and 1 is the worst.In that case, the best result would be to take into quality of prediction based upon position in account\n",
    "# So for merge with stride of 0.5, for eg. [12345432100000] AND [00000123454321], should be [1234543454321] instead of [1234543214321] that you will currently get. \n",
    "# However, in case the values are strecthed before hand this problem will be minimized\n",
    "    res[row:row+he, col:col+wi] =  resultant\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask, operator):\n",
    "    tm = np.stack(batch, axis = 0)\n",
    "    prediction = model.predict(tm)\n",
    "    for i in range(len(batch_pos)):\n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis = -1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi, operator)\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def detect_tree(ndvi_img, pan_img, width=256, height=256, stride = 128, normalize=True):\n",
    "    assert ndvi_img.meta['width'] == pan_img.meta['width'] and ndvi_img.meta['height'] == pan_img.meta['height']\n",
    "    nols, nrows = ndvi_img.meta['width'], ndvi_img.meta['height']\n",
    "    meta = ndvi_img.meta.copy()\n",
    "    if 'float' not in meta['dtype']: #The prediction is a float so we keep it as float to be consistent with the prediction. \n",
    "        meta['dtype'] = np.float32\n",
    "    offsets = product(range(0, nols, stride), range(0, nrows, stride))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "#     print(nrows, nols)\n",
    "\n",
    "    mask = np.ones((nrows, nols), dtype=meta['dtype']) * -1\n",
    "\n",
    "#     mask = mask -1 # Note: The initial mask is initialized with -1 instead of zero to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = [ ]\n",
    "    for col_off, row_off in  tqdm(offsets):\n",
    "        print(0)\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ndvi_img.transform)\n",
    "        patch = np.zeros((height, width, 2)) #Add zero padding in case of corner images\n",
    "        ndvi_sm = ndvi_img.read(window=window)\n",
    "        pan_sm = pan_img.read(window=window)\n",
    "        temp_im = np.stack((ndvi_sm, pan_sm), axis = -1)\n",
    "        temp_im = np.squeeze(temp_im)\n",
    "        \n",
    "        if normalize:\n",
    "            temp_im = image_normalize(temp_im, axis=(0,1)) # Normalize the image along the width and height i.e. independently per channel\n",
    "            \n",
    "        patch[:window.height, :window.width] = temp_im\n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        if (len(batch) == config.BATCH_SIZE):\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask, 'MIN')\n",
    "#             print(mask)\n",
    "            batch = []\n",
    "            batch_pos = []\n",
    "            \n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask, 'MIN')\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return(mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'id': 'str', 'canopy': 'float:15.2',},\n",
    "    }\n",
    "\n",
    "def drawPolygons(polygons, shape):\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    for polygon in polygons:\n",
    "        xy = [(point[1], point[0]) for point in polygon]\n",
    "        draw.polygon(xy=xy, outline=255, fill=255)\n",
    "    mask = np.array(mask)#, dtype=bool)   \n",
    "    return(mask)\n",
    "\n",
    "def transformToXY(polygons, transform):\n",
    "    tp = []\n",
    "    for polygon in polygons:\n",
    "        rows, cols = zip(*polygon)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tp.append(list(zip(x,y)))\n",
    "    return (tp)\n",
    "\n",
    "def createShapefileObject(polygons, meta, wfile):\n",
    "    with fiona.open(wfile, 'w', crs=meta.get('crs').to_dict(), driver='ESRI Shapefile', schema=schema) as sink:\n",
    "        for idx, mp in enumerate(polygons):\n",
    "            try:\n",
    "#                 poly = Polygon(poly)\n",
    "    #             assert mp.is_valid\n",
    "    #             assert mp.geom_type == 'Polygon'\n",
    "                sink.write({\n",
    "                    'geometry': mapping(mp),\n",
    "                    'properties': {'id': str(idx), 'canopy': mp.area},\n",
    "                })\n",
    "            except:\n",
    "                print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "#                 print(mp)\n",
    "\n",
    "# Generate a mask with polygons\n",
    "def transformContoursToXY(contours, transform = None):\n",
    "    tp = []\n",
    "    for cnt in contours:\n",
    "        pl = cnt[:, 0, :]\n",
    "        cols, rows = zip(*pl)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tl = [list(i) for i in zip(x, y)]\n",
    "        tp.append(tl)\n",
    "    return (tp)\n",
    "\n",
    "\n",
    "def mask_to_polygons(maskF, transform):\n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    th = 0.5\n",
    "    mask = maskF.copy()\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "    mask = ((mask) * 255).astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    #Convert contours from image coordinate to xy coordinate\n",
    "    contours = transformContoursToXY(contours, transform)\n",
    "    if not contours: #TODO: Raise an error maybe\n",
    "        print('Warning: No contours/polygons detected!!')\n",
    "        return [Polygon()]\n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "\n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if idx not in child_contours: #and cv2.contourArea(cnt) >= min_area: #Do we need to check for min_area??\n",
    "            try:\n",
    "                poly = Polygon(\n",
    "                    shell=cnt,\n",
    "                    holes=[c for c in cnt_children.get(idx, [])])\n",
    "                           #if cv2.contourArea(c) >= min_area]) #Do we need to check for min_area??\n",
    "                all_polygons.append(poly)\n",
    "            except:\n",
    "                pass\n",
    "#                 print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "    print(len(all_polygons))\n",
    "    return(all_polygons)\n",
    "\n",
    "def create_contours_shapefile(mask, meta, out_fn):\n",
    "    res = mask_to_polygons(mask, meta['transform'])\n",
    "#     res = transformToXY(contours, meta['transform'])\n",
    "    createShapefileObject(res, meta, out_fn)\n",
    "\n",
    "\n",
    "def writeMaskToDisk(detected_mask, detected_meta, wp, write_as_type = 'uint8', th = 0.5, create_countors = False):\n",
    "    # Convert to correct required before writing\n",
    "    if 'float' in str(detected_meta['dtype']) and 'int' in write_as_type:\n",
    "        print(f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}')\n",
    "        detected_mask[detected_mask<th]=0\n",
    "        detected_mask[detected_mask>=th]=1\n",
    "        detected_mask = detected_mask.astype(write_as_type)\n",
    "        detected_meta['dtype'] =  write_as_type\n",
    "        \n",
    "    with rasterio.open(wp, 'w', **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)\n",
    "    if create_countors:\n",
    "        wp = wp.replace('.tif', '.shp')\n",
    "        create_contours_shapefile(detected_mask, detected_meta, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../India_test_area/wv03_20190407054002_1040010048338400_19apr07054002-m1bs-503158889080_01_p006_utm43n_b357_pan_ndvi.tif', 'wv03_20190407054002_1040010048338400_19apr07054002-m1bs-503158889080_01_p006_utm43n_b357_pan_ndvi.tif')]\n",
      "../India_test_area/wv03_20190407054002_1040010048338400_19apr07054002-m1bs-503158889080_01_p006_utm43n_b357_pan_ndvi.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 184.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:00, 189.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:00, 150.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134it [00:00, 168.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [00:00, 177.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "191it [00:01, 180.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:46:22.519452: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-01 15:46:22.519953: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n",
      "2022-04-01 15:46:22.738077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-01 15:46:24.196577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "210it [00:05, 12.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [00:06, 39.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/local/50572333/ipykernel_18180/49349626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndvi_fn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpan_fn_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mdetectedMask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectedMeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRIDE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetectedMask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectedMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#Write the mask to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/local/50572333/ipykernel_18180/3804556190.py\u001b[0m in \u001b[0;36mdetect_tree\u001b[0;34m(ndvi_img, pan_img, width, height, stride, normalize)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtemp_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Normalize the image along the width and height i.e. independently per channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_im\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ufs18/home-003/parakhni/An-unexpectedly-large-count-of-trees-in-the-western-Sahara-and-Sahel/notebooks/core/frame_info.py\u001b[0m in \u001b[0;36mimage_normalize\u001b[0;34m(im, axis, c)\u001b[0m\n\u001b[1;32m      7\u001b[0m     '''\n\u001b[1;32m      8\u001b[0m     Normalize to zero mean and unit standard deviation along the given axis'''\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p392/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    260\u001b[0m def _std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n\u001b[1;32m    261\u001b[0m          where=True):\n\u001b[0;32m--> 262\u001b[0;31m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0m\u001b[1;32m    263\u001b[0m                keepdims=keepdims, where=where)\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p392/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# Compute degrees of freedom and make sure it is not negative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Predict trees in the all the files in the input image dir\n",
    "# Depending upon the available RAM, images may not to be split before running this cell.\n",
    "# Use the Auxiliary-2-SplitRasterToAnalyse if the images are too big to be analysed in memory.\n",
    "# tf.Session()\n",
    "\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(config.input_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(config.input_image_type) and config.ndvi_fn_st in file:\n",
    "             all_files.append((os.path.join(root, file), file))\n",
    "print(all_files)\n",
    "masks = []\n",
    "for fullPath, filename in all_files:\n",
    "    outputFile = os.path.join(config.output_dir, filename.replace(config.ndvi_fn_st, config.output_prefix) )\n",
    "    if not os.path.isfile(outputFile) or config.overwrite_analysed_files: \n",
    "        with rasterio.open(fullPath) as ndvi:\n",
    "            with rasterio.open(fullPath.replace(config.ndvi_fn_st, config.pan_fn_st)) as pan:\n",
    "                print(fullPath)\n",
    "                detectedMask, detectedMeta = detect_tree(ndvi, pan, width = config.WIDTH, height = config.HEIGHT, stride = config.STRIDE) # WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\n",
    "                masks.append((detectedMask, detectedMeta))\n",
    "                #Write the mask to file\n",
    "                writeMaskToDisk(detectedMask, detectedMeta, outputFile, write_as_type = config.output_dtype, th = 0.5, create_countors = True)                \n",
    "    else:\n",
    "        print('File already analysed!', fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted image\n",
    "sampleImage = config.output_prefix + config.output_image_type\n",
    "fn = os.path.join(config.output_dir, sampleImage )\n",
    "predicted_img = rasterio.open(fn)\n",
    "p = predicted_img.read()\n",
    "np.unique(p, return_counts=True)\n",
    "plt.imshow(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
